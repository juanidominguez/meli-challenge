{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29a3ba3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Setup complete: paths and directories ready\n"
     ]
    }
   ],
   "source": [
    "# Setup: Add src to path and create directories\n",
    "import sys, os\n",
    "sys.path.insert(0, os.path.join('..', 'src'))\n",
    "for d in ['results', 'models']: \n",
    "    os.makedirs(f'../{d}', exist_ok=True)\n",
    "print(\"✅ Setup complete: paths and directories ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0210db8e-484d-4d13-8061-1cd7c00c8ff7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T00:17:15.726978Z",
     "iopub.status.busy": "2025-07-10T00:17:15.726654Z",
     "iopub.status.idle": "2025-07-10T00:17:16.788539Z",
     "shell.execute_reply": "2025-07-10T00:17:16.787917Z",
     "shell.execute_reply.started": "2025-07-10T00:17:15.726945Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Feature Engineering Pipeline for MercadoLibre Product Classification\n",
    "==================================================================\n",
    "\n",
    "This module provides a comprehensive feature engineering pipeline for transforming\n",
    "raw product data into features suitable for machine learning models.\n",
    "\n",
    "The pipeline includes:\n",
    "- Data normalization and cleaning\n",
    "- Feature extraction from complex fields (timestamps, text, lists)\n",
    "- Categorical encoding and numerical transformations\n",
    "- Seller and product metadata enrichment\n",
    "\n",
    "Usage:\n",
    "    from feature_engineering_pipeline import make_full_pipeline\n",
    "    \n",
    "    pipeline = make_full_pipeline(target_name='condition')\n",
    "    X_processed = pipeline.fit_transform(X_train, y_train)\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "import re\n",
    "import ast\n",
    "import math\n",
    "import unicodedata\n",
    "import json\n",
    "import logging\n",
    "from typing import List, Tuple, Union, Optional, Any, cast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import category_encoders as ce\n",
    "from feature_engine.imputation import CategoricalImputer\n",
    "from feature_engine.encoding import OneHotEncoder, RareLabelEncoder, MeanEncoder\n",
    "from feature_engine.selection import DropFeatures\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c618dad-bb26-4968-84f6-751f002cdaa7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T00:17:16.789667Z",
     "iopub.status.busy": "2025-07-10T00:17:16.789304Z",
     "iopub.status.idle": "2025-07-10T00:17:16.794165Z",
     "shell.execute_reply": "2025-07-10T00:17:16.793693Z",
     "shell.execute_reply.started": "2025-07-10T00:17:16.789647Z"
    }
   },
   "outputs": [],
   "source": [
    "# ════════════════════════════════════════════════════════════════════════\n",
    "# Constants and Configuration\n",
    "# ════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "# Tokens that should be treated as null/missing values\n",
    "NULL_TOKENS = {'', ' ', 'na', 'n/a', 'none', 'null', 'nan', '[]', '{}'}\n",
    "\n",
    "# Listing type hierarchy mapping\n",
    "LISTING_TYPE_HIERARCHY = {\n",
    "    'free': 0,\n",
    "    'bronze': 1,\n",
    "    'silver': 2,\n",
    "    'gold': 3,\n",
    "    'gold_special': 4,\n",
    "    'gold_premium': 5,\n",
    "    'gold_pro': 6\n",
    "}\n",
    "\n",
    "# Columns to drop from the dataset\n",
    "COLUMNS_TO_DROP = [\n",
    "    'differential_pricing', 'subtitle', 'shipping_dimensions', 'original_price',\n",
    "    'shipping_methods', 'site_id', 'listing_source', 'coverage_areas',\n",
    "    'international_delivery_mode', 'seller_address_country_name',\n",
    "    'seller_address_country_id', 'seller_address_city_name', 'deal_ids',\n",
    "    'id', 'permalink', 'thumbnail', 'secure_thumbnail', 'base_price',\n",
    "    'parent_item_id', 'variations', 'title', 'seller_address_state_id',\n",
    "    'seller_address_city_id', 'sub_status', 'official_store_id',\n",
    "    'video_id', 'catalog_product_id', 'shipping_tags', 'shipping_free_methods',\n",
    "    'stop_time', 'last_updated', 'date_created'\n",
    "]\n",
    "\n",
    "# Columns for one-hot encoding\n",
    "ONE_HOT_COLUMNS = ['buying_mode', 'seller_address_state_name', 'shipping_mode', 'status']\n",
    "\n",
    "# Boolean columns that need special handling\n",
    "BOOLEAN_COLUMNS = ['automatic_relist', 'shipping_local_pick_up', 'shipping_free_shipping']\n",
    "\n",
    "# Seller volume thresholds\n",
    "HIGH_VOLUME_THRESHOLD = 50\n",
    "HIGH_INVENTORY_THRESHOLD = 10\n",
    "LOW_PRICE_THRESHOLD = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21c0b6d9-7e7d-4deb-822f-5eb7cfe7dcbc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T00:17:16.795580Z",
     "iopub.status.busy": "2025-07-10T00:17:16.795342Z",
     "iopub.status.idle": "2025-07-10T00:17:16.801551Z",
     "shell.execute_reply": "2025-07-10T00:17:16.801104Z",
     "shell.execute_reply.started": "2025-07-10T00:17:16.795563Z"
    }
   },
   "outputs": [],
   "source": [
    "# ════════════════════════════════════════════════════════════════════════\n",
    "# Helper Functions\n",
    "# ════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "def normalize_txt(s: str) -> str:\n",
    "    \"\"\"\n",
    "    Normalize text by removing accents, converting to lowercase, and cleaning whitespace.\n",
    "    \n",
    "    Args:\n",
    "        s: Input string to normalize\n",
    "        \n",
    "    Returns:\n",
    "        Normalized string\n",
    "    \"\"\"\n",
    "    if not isinstance(s, str):\n",
    "        s = str(s)\n",
    "    \n",
    "    # Remove accents and convert to ASCII\n",
    "    s = unicodedata.normalize('NFKD', s).encode('ascii', 'ignore').decode('ascii')\n",
    "    \n",
    "    # Convert to lowercase and normalize whitespace\n",
    "    return re.sub(r'\\s+', ' ', s.lower()).strip()\n",
    "\n",
    "\n",
    "def warranty_to_months(text: Any) -> int:\n",
    "    \"\"\"\n",
    "    Extract warranty duration in months from text.\n",
    "    \n",
    "    Args:\n",
    "        text: Warranty text description\n",
    "        \n",
    "    Returns:\n",
    "        -1: No warranty\n",
    "         0: Has warranty but duration not specified\n",
    "        >0: Warranty duration in months\n",
    "    \"\"\"\n",
    "    if pd.isna(text):\n",
    "        return -1\n",
    "    \n",
    "    try:\n",
    "        txt = normalize_txt(str(text))\n",
    "        \n",
    "        if txt in NULL_TOKENS or re.search(r'\\b(?:sin|no)\\s+garant', txt, re.I):\n",
    "            return -1\n",
    "        \n",
    "        # Regular expressions for time units\n",
    "        re_units = {\n",
    "            'year': re.compile(r'(?:un|\\d+)\\s*a(?:n|ñ)o?s?'),\n",
    "            'month': re.compile(r'(?:un|\\d+)\\s*mes(?:es)?'),\n",
    "            'day': re.compile(r'(?:un|\\d+)\\s*d[ií]a?s?'),\n",
    "        }\n",
    "        \n",
    "        for unit, rgx in re_units.items():\n",
    "            match = rgx.search(txt)\n",
    "            if match:\n",
    "                # Extract number or default to 1 for \"un\"\n",
    "                token = re.search(r'\\d+', match.group())\n",
    "                num = int(token.group()) if token else 1\n",
    "                \n",
    "                if unit == 'year':\n",
    "                    return num * 12\n",
    "                elif unit == 'day':\n",
    "                    return max(1, round(num / 30))\n",
    "                else:  # month\n",
    "                    return num\n",
    "        \n",
    "        # Check for warranty keywords\n",
    "        if re.search(r'(garant\\w*.*\\b(?:si|con|fabric|fabr|oficial|total)\\b)|'\n",
    "                    r'\\b(?:de|del)\\s+fabr(?:ic(?:a|ante)?|)\\b', txt, re.I):\n",
    "            return 0\n",
    "        \n",
    "        return -1\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.warning(f\"Error processing warranty text '{text}': {e}\")\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12fc0bcf-80d8-498a-9cd8-1cff33f44b52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T00:17:16.802363Z",
     "iopub.status.busy": "2025-07-10T00:17:16.802157Z",
     "iopub.status.idle": "2025-07-10T00:17:16.808118Z",
     "shell.execute_reply": "2025-07-10T00:17:16.807668Z",
     "shell.execute_reply.started": "2025-07-10T00:17:16.802345Z"
    }
   },
   "outputs": [],
   "source": [
    "# ════════════════════════════════════════════════════════════════════════\n",
    "# Transformer Classes\n",
    "# ════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "class CatNullNormalizer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Normalize null values in categorical columns.\n",
    "    \n",
    "    Converts empty collections, null tokens, and various null representations\n",
    "    to pandas NA for consistent handling downstream.\n",
    "    \"\"\"\n",
    "    \n",
    "    def fit(self, X: pd.DataFrame, y: Optional[pd.Series] = None) -> 'CatNullNormalizer':\n",
    "        \"\"\"\n",
    "        Fit the transformer by identifying categorical columns.\n",
    "        \n",
    "        Args:\n",
    "            X: Input DataFrame\n",
    "            y: Target variable (ignored)\n",
    "            \n",
    "        Returns:\n",
    "            Self for method chaining\n",
    "        \"\"\"\n",
    "        self.cols = X.select_dtypes(include='object').columns.tolist()\n",
    "        return self\n",
    "    \n",
    "    @staticmethod\n",
    "    def _to_na(x: Any) -> Any:\n",
    "        \"\"\"\n",
    "        Convert various null representations to pandas NA.\n",
    "        \n",
    "        Args:\n",
    "            x: Input value\n",
    "            \n",
    "        Returns:\n",
    "            pandas NA if value represents null, otherwise original value\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Handle collections\n",
    "            if isinstance(x, (list, tuple, set, dict, np.ndarray)):\n",
    "                return pd.NA if len(x) == 0 else x\n",
    "            \n",
    "            # Handle explicit nulls\n",
    "            if x is None or (isinstance(x, float) and math.isnan(x)) or pd.isna(x):\n",
    "                return pd.NA\n",
    "            \n",
    "            # Handle string representations of null\n",
    "            if str(x).strip().lower() in NULL_TOKENS:\n",
    "                return pd.NA\n",
    "            \n",
    "            return x\n",
    "        except Exception:\n",
    "            return x\n",
    "    \n",
    "    def transform(self, X: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Transform categorical columns by normalizing null values.\n",
    "        \n",
    "        Args:\n",
    "            X: Input DataFrame\n",
    "            \n",
    "        Returns:\n",
    "            Transformed DataFrame\n",
    "        \"\"\"\n",
    "        out = X.copy()\n",
    "        for col in self.cols:\n",
    "            if col in out.columns:\n",
    "                out[col] = out[col].map(self._to_na)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3c2a340-f803-4edd-b2c6-409791f44060",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T00:17:16.809003Z",
     "iopub.status.busy": "2025-07-10T00:17:16.808770Z",
     "iopub.status.idle": "2025-07-10T00:17:16.814968Z",
     "shell.execute_reply": "2025-07-10T00:17:16.814519Z",
     "shell.execute_reply.started": "2025-07-10T00:17:16.808986Z"
    }
   },
   "outputs": [],
   "source": [
    "class TimeFeatures(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Extract time-based features from timestamp columns.\n",
    "    \n",
    "    Handles multiple timestamp formats including epoch milliseconds,\n",
    "    epoch seconds, and ISO string formats.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, col: str = 'start_time'):\n",
    "        \"\"\"\n",
    "        Initialize the transformer.\n",
    "        \n",
    "        Args:\n",
    "            col: Name of the timestamp column to process\n",
    "        \"\"\"\n",
    "        self.col = col\n",
    "    \n",
    "    def fit(self, X: pd.DataFrame, y: Optional[pd.Series] = None) -> 'TimeFeatures':\n",
    "        \"\"\"Fit method (no-op for this transformer).\"\"\"\n",
    "        return self\n",
    "    \n",
    "    def _parse_timestamp(self, s: pd.Series) -> pd.Series:\n",
    "        \"\"\"\n",
    "        Parse timestamps from various formats.\n",
    "        \n",
    "        Args:\n",
    "            s: Series containing timestamps\n",
    "            \n",
    "        Returns:\n",
    "            Series with parsed datetime objects\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Try milliseconds first\n",
    "            ts_ms = pd.to_datetime(s, unit='ms', errors='coerce', utc=True)\n",
    "            \n",
    "            # Try seconds for values that failed milliseconds\n",
    "            ts_s = pd.to_datetime(s, unit='s', errors='coerce', utc=True)\n",
    "            \n",
    "            # For numeric values, prefer milliseconds, fallback to seconds\n",
    "            ts_numeric = np.where(\n",
    "                s.astype(str).str.isnumeric(),\n",
    "                ts_ms.fillna(ts_s),\n",
    "                pd.to_datetime(s, errors='coerce', utc=True)\n",
    "            )\n",
    "            \n",
    "            return pd.Series(ts_numeric).dt.tz_localize(None)\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Error parsing timestamps: {e}\")\n",
    "            return pd.Series([pd.NaT] * len(s))\n",
    "    \n",
    "    def transform(self, X: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Transform timestamp column into time-based features.\n",
    "        \n",
    "        Args:\n",
    "            X: Input DataFrame\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame with time features added and original column removed\n",
    "        \"\"\"\n",
    "        if self.col not in X.columns:\n",
    "            logger.warning(f\"Column '{self.col}' not found in DataFrame\")\n",
    "            return X\n",
    "        \n",
    "        out = X.copy()\n",
    "        ts = self._parse_timestamp(pd.Series(out[self.col]))\n",
    "        \n",
    "        out['start_hour'] = ts.dt.hour.astype('Int8')\n",
    "        out['start_dow'] = ts.dt.weekday.astype('Int8')\n",
    "        out['start_month'] = ts.dt.month.astype('Int8')\n",
    "        \n",
    "        return out.drop(columns=self.col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55772ae7-bd4e-445f-b8ec-85587e6837d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T00:17:16.815681Z",
     "iopub.status.busy": "2025-07-10T00:17:16.815507Z",
     "iopub.status.idle": "2025-07-10T00:17:16.820910Z",
     "shell.execute_reply": "2025-07-10T00:17:16.820484Z",
     "shell.execute_reply.started": "2025-07-10T00:17:16.815666Z"
    }
   },
   "outputs": [],
   "source": [
    "class NumericIndicators(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Create numeric indicator features and transformations.\n",
    "    \n",
    "    Generates binary flags for high inventory and low price,\n",
    "    and creates log-transformed price feature.\n",
    "    \"\"\"\n",
    "    \n",
    "    def fit(self, X: pd.DataFrame, y: Optional[pd.Series] = None) -> 'NumericIndicators':\n",
    "        \"\"\"Fit method (no-op for this transformer).\"\"\"\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Transform numeric columns into indicator features.\n",
    "        \n",
    "        Args:\n",
    "            X: Input DataFrame\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame with numeric indicators added\n",
    "        \"\"\"\n",
    "        out = X.copy()\n",
    "        \n",
    "        # Create indicator features\n",
    "        if 'initial_quantity' in out.columns:\n",
    "            out['high_inventory_flag'] = (out['initial_quantity'] > HIGH_INVENTORY_THRESHOLD).astype('int8')\n",
    "        \n",
    "        if 'price' in out.columns:\n",
    "            out['low_price_flag'] = (out['price'] < LOW_PRICE_THRESHOLD).astype('int8')\n",
    "            out['log_price'] = np.log1p(out['price']).astype('float32')\n",
    "            out = out.drop(columns='price')\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91c3b964-c56e-40a5-9af6-5984212df677",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T00:17:16.821749Z",
     "iopub.status.busy": "2025-07-10T00:17:16.821528Z",
     "iopub.status.idle": "2025-07-10T00:17:16.826994Z",
     "shell.execute_reply": "2025-07-10T00:17:16.826553Z",
     "shell.execute_reply.started": "2025-07-10T00:17:16.821732Z"
    }
   },
   "outputs": [],
   "source": [
    "class ListingTypeOrdinal(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Convert listing type to ordinal encoding based on hierarchy.\n",
    "    \n",
    "    Maps listing types to numerical values reflecting their hierarchy\n",
    "    in the MercadoLibre ecosystem.\n",
    "    \"\"\"\n",
    "    \n",
    "    def fit(self, X: pd.DataFrame, y: Optional[pd.Series] = None) -> 'ListingTypeOrdinal':\n",
    "        \"\"\"Fit method (no-op for this transformer).\"\"\"\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Transform listing type to ordinal values.\n",
    "        \n",
    "        Args:\n",
    "            X: Input DataFrame\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame with ordinal listing type feature\n",
    "        \"\"\"\n",
    "        out = X.copy()\n",
    "        \n",
    "        if 'listing_type_id' in out.columns:\n",
    "            out['listing_type_rank'] = (\n",
    "                out['listing_type_id']\n",
    "                .map(lambda x: LISTING_TYPE_HIERARCHY.get(x, -1))\n",
    "                .astype('Int8')\n",
    "            )\n",
    "            out = out.drop(columns='listing_type_id')\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba4e6452-2ee6-43a9-80b8-c9919a4fe4ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T00:17:16.827830Z",
     "iopub.status.busy": "2025-07-10T00:17:16.827601Z",
     "iopub.status.idle": "2025-07-10T00:17:16.833265Z",
     "shell.execute_reply": "2025-07-10T00:17:16.832767Z",
     "shell.execute_reply.started": "2025-07-10T00:17:16.827813Z"
    }
   },
   "outputs": [],
   "source": [
    "class SellerFeatures(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Extract seller-related features.\n",
    "    \n",
    "    Creates features based on seller activity volume including\n",
    "    log-transformed volume and high-volume indicators.\n",
    "    \"\"\"\n",
    "    \n",
    "    def fit(self, X: pd.DataFrame, y: Optional[pd.Series] = None) -> 'SellerFeatures':\n",
    "        \"\"\"\n",
    "        Fit the transformer by calculating seller volumes.\n",
    "        \n",
    "        Args:\n",
    "            X: Input DataFrame\n",
    "            y: Target variable (ignored)\n",
    "            \n",
    "        Returns:\n",
    "            Self for method chaining\n",
    "        \"\"\"\n",
    "        if 'seller_id' in X.columns:\n",
    "            self.seller_counts = X['seller_id'].astype('str').value_counts()\n",
    "        else:\n",
    "            self.seller_counts = pd.Series(dtype='int64')\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Transform seller information into volume features.\n",
    "        \n",
    "        Args:\n",
    "            X: Input DataFrame\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame with seller features added\n",
    "        \"\"\"\n",
    "        out = X.copy()\n",
    "        \n",
    "        if 'seller_id' in out.columns:\n",
    "            # Calculate seller volume\n",
    "            volume = out['seller_id'].astype('str').map(lambda x: self.seller_counts.get(x, 0))\n",
    "            \n",
    "            out['seller_volume_log'] = np.log1p(volume).astype('float32')\n",
    "            out['seller_high_volume'] = (volume > HIGH_VOLUME_THRESHOLD).astype('int8')\n",
    "            \n",
    "            out = out.drop(columns='seller_id')\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0441d132-1931-495d-97a0-0e64ace094f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T00:17:16.834905Z",
     "iopub.status.busy": "2025-07-10T00:17:16.834677Z",
     "iopub.status.idle": "2025-07-10T00:17:16.839340Z",
     "shell.execute_reply": "2025-07-10T00:17:16.838905Z",
     "shell.execute_reply.started": "2025-07-10T00:17:16.834888Z"
    }
   },
   "outputs": [],
   "source": [
    "class WarrantyTransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transform warranty information into structured features.\n",
    "    \n",
    "    Extracts warranty duration and creates indicators for\n",
    "    warranty presence and duration specification.\n",
    "    \"\"\"\n",
    "    \n",
    "    def fit(self, X: pd.DataFrame, y: Optional[pd.Series] = None) -> 'WarrantyTransformer':\n",
    "        \"\"\"Fit method (no-op for this transformer).\"\"\"\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Transform warranty text into structured features.\n",
    "        \n",
    "        Args:\n",
    "            X: Input DataFrame\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame with warranty features\n",
    "        \"\"\"\n",
    "        out = X.copy()\n",
    "        \n",
    "        if 'warranty' in out.columns:\n",
    "            months = out['warranty'].map(warranty_to_months).astype('int16')\n",
    "            \n",
    "            out['warranty_months'] = months\n",
    "            out['warranty_duration_specified'] = (months >= 0).astype('int8')\n",
    "            \n",
    "            out = out.drop(columns='warranty')\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3317744d-6789-40e8-9b22-d7e7e2a91ec4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T00:17:16.839977Z",
     "iopub.status.busy": "2025-07-10T00:17:16.839804Z",
     "iopub.status.idle": "2025-07-10T00:17:16.845678Z",
     "shell.execute_reply": "2025-07-10T00:17:16.845221Z",
     "shell.execute_reply.started": "2025-07-10T00:17:16.839961Z"
    }
   },
   "outputs": [],
   "source": [
    "class AttrDescFlags(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Create flags and counts for attributes and descriptions.\n",
    "    \n",
    "    Generates features indicating the presence and count of\n",
    "    product attributes and descriptions.\n",
    "    \"\"\"\n",
    "    \n",
    "    def fit(self, X: pd.DataFrame, y: Optional[pd.Series] = None) -> 'AttrDescFlags':\n",
    "        \"\"\"Fit method (no-op for this transformer).\"\"\"\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Transform attributes and descriptions into count features.\n",
    "        \n",
    "        Args:\n",
    "            X: Input DataFrame\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame with attribute and description features\n",
    "        \"\"\"\n",
    "        out = X.copy()\n",
    "        \n",
    "        if 'attributes' in out.columns:\n",
    "            n_attrs = out['attributes'].apply(\n",
    "                lambda v: len(v) if isinstance(v, list) else 0\n",
    "            ).astype('int16')\n",
    "            \n",
    "            out['n_attributes'] = n_attrs\n",
    "            out['has_attributes'] = (n_attrs > 0).astype('int8')\n",
    "            out = out.drop(columns='attributes')\n",
    "        \n",
    "        if 'descriptions' in out.columns:\n",
    "            out['has_description'] = out['descriptions'].apply(\n",
    "                lambda v: int(bool(isinstance(v, list) and len(v)))\n",
    "            ).astype('int8')\n",
    "            out = out.drop(columns='descriptions')\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25b393c1-0e48-4db0-971e-64767636f06c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T00:17:16.846409Z",
     "iopub.status.busy": "2025-07-10T00:17:16.846238Z",
     "iopub.status.idle": "2025-07-10T00:17:16.852636Z",
     "shell.execute_reply": "2025-07-10T00:17:16.852182Z",
     "shell.execute_reply.started": "2025-07-10T00:17:16.846393Z"
    }
   },
   "outputs": [],
   "source": [
    "class PaymentMethodFeatures(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Extract features from payment method information.\n",
    "    \n",
    "    Analyzes payment methods to create features for card acceptance,\n",
    "    pickup options, and payment method diversity.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.card_pattern = re.compile(r'visa|master|american|diners|tarjeta', re.I)\n",
    "        self.pickup_pattern = re.compile(r'(acordar|reembolso)', re.I)\n",
    "    \n",
    "    def fit(self, X: pd.DataFrame, y: Optional[pd.Series] = None) -> 'PaymentMethodFeatures':\n",
    "        \"\"\"Fit method (no-op for this transformer).\"\"\"\n",
    "        return self\n",
    "    \n",
    "    def _summarize_payment_methods(self, methods: Any) -> Tuple[int, int, int]:\n",
    "        \"\"\"\n",
    "        Summarize payment method information.\n",
    "        \n",
    "        Args:\n",
    "            methods: Payment methods data\n",
    "            \n",
    "        Returns:\n",
    "            Tuple of (count, accepts_card, pay_on_pickup)\n",
    "        \"\"\"\n",
    "        if not isinstance(methods, list) or not methods:\n",
    "            return 0, 0, 0\n",
    "        \n",
    "        try:\n",
    "            descriptions = [m.get('description', '') for m in methods if isinstance(m, dict)]\n",
    "            \n",
    "            count = len(descriptions)\n",
    "            accepts_card = int(any(self.card_pattern.search(desc) for desc in descriptions))\n",
    "            pay_on_pickup = int(any(self.pickup_pattern.search(desc) for desc in descriptions))\n",
    "            \n",
    "            return count, accepts_card, pay_on_pickup\n",
    "        except Exception:\n",
    "            return 0, 0, 0\n",
    "    \n",
    "    def transform(self, X: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Transform payment method information into features.\n",
    "        \n",
    "        Args:\n",
    "            X: Input DataFrame\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame with payment method features\n",
    "        \"\"\"\n",
    "        out = X.copy()\n",
    "        \n",
    "        if 'non_mercado_pago_payment_methods' in out.columns:\n",
    "            payment_summary = out['non_mercado_pago_payment_methods'].apply(\n",
    "                self._summarize_payment_methods\n",
    "            )\n",
    "            \n",
    "            out['n_extra_pay_methods'] = payment_summary.map(lambda t: t[0]).astype('int8')\n",
    "            out['accepts_card'] = payment_summary.map(lambda t: t[1]).astype('int8')\n",
    "            out['pay_on_pickup'] = payment_summary.map(lambda t: t[2]).astype('int8')\n",
    "            \n",
    "            out = out.drop(columns='non_mercado_pago_payment_methods')\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79cb43eb-b837-459b-be05-d5475e0615bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T00:17:16.853354Z",
     "iopub.status.busy": "2025-07-10T00:17:16.853180Z",
     "iopub.status.idle": "2025-07-10T00:17:16.858707Z",
     "shell.execute_reply": "2025-07-10T00:17:16.858261Z",
     "shell.execute_reply.started": "2025-07-10T00:17:16.853339Z"
    }
   },
   "outputs": [],
   "source": [
    "class PictureCount(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Count the number of pictures for each product.\n",
    "    \n",
    "    Creates a feature indicating the number of product images,\n",
    "    which can be important for product appeal and completeness.\n",
    "    \"\"\"\n",
    "    \n",
    "    def fit(self, X: pd.DataFrame, y: Optional[pd.Series] = None) -> 'PictureCount':\n",
    "        \"\"\"Fit method (no-op for this transformer).\"\"\"\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Transform picture information into count feature.\n",
    "        \n",
    "        Args:\n",
    "            X: Input DataFrame\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame with picture count feature\n",
    "        \"\"\"\n",
    "        out = X.copy()\n",
    "        \n",
    "        if 'pictures' in out.columns:\n",
    "            out['n_pictures'] = out['pictures'].apply(\n",
    "                lambda v: len(v) if isinstance(v, list) else 0\n",
    "            ).astype('int16')\n",
    "            out = out.drop(columns='pictures')\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b41c442-18c7-45c0-b5c0-1cf0b7f1cd34",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T00:17:16.859430Z",
     "iopub.status.busy": "2025-07-10T00:17:16.859259Z",
     "iopub.status.idle": "2025-07-10T00:17:16.864993Z",
     "shell.execute_reply": "2025-07-10T00:17:16.864545Z",
     "shell.execute_reply.started": "2025-07-10T00:17:16.859414Z"
    }
   },
   "outputs": [],
   "source": [
    "class TagFeatures(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Extract features from product tags.\n",
    "    \n",
    "    Creates features for tag presence and count, which can\n",
    "    indicate product categorization and marketing effort.\n",
    "    \"\"\"\n",
    "    \n",
    "    def fit(self, X: pd.DataFrame, y: Optional[pd.Series] = None) -> 'TagFeatures':\n",
    "        \"\"\"Fit method (no-op for this transformer).\"\"\"\n",
    "        return self\n",
    "    \n",
    "    def _parse_tags(self, val: Any) -> List[str]:\n",
    "        \"\"\"\n",
    "        Parse tags from various formats.\n",
    "        \n",
    "        Args:\n",
    "            val: Tag data in various formats\n",
    "            \n",
    "        Returns:\n",
    "            List of parsed tags\n",
    "        \"\"\"\n",
    "        if isinstance(val, list):\n",
    "            return val\n",
    "        \n",
    "        if val is None or (isinstance(val, float) and pd.isna(val)):\n",
    "            return []\n",
    "        \n",
    "        try:\n",
    "            if isinstance(val, str):\n",
    "                parsed = ast.literal_eval(val)\n",
    "                return parsed if isinstance(parsed, list) else []\n",
    "            return []\n",
    "        except Exception:\n",
    "            return []\n",
    "    \n",
    "    def transform(self, X: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Transform tag information into features.\n",
    "        \n",
    "        Args:\n",
    "            X: Input DataFrame\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame with tag features\n",
    "        \"\"\"\n",
    "        out = X.copy()\n",
    "        \n",
    "        if 'tags' in out.columns:\n",
    "            tag_lists = out['tags'].apply(self._parse_tags)\n",
    "            \n",
    "            out['has_tags'] = (tag_lists.str.len() > 0).astype('int8')\n",
    "            out['n_tags'] = tag_lists.str.len().astype('int16')\n",
    "            \n",
    "            out = out.drop(columns='tags')\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cdffe8c8-429b-4da3-a12d-aca67fd156ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T00:17:16.865770Z",
     "iopub.status.busy": "2025-07-10T00:17:16.865546Z",
     "iopub.status.idle": "2025-07-10T00:17:16.870874Z",
     "shell.execute_reply": "2025-07-10T00:17:16.870430Z",
     "shell.execute_reply.started": "2025-07-10T00:17:16.865753Z"
    }
   },
   "outputs": [],
   "source": [
    "class CurrencyBinary(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Create binary feature for currency type.\n",
    "    \n",
    "    Creates an indicator for USD vs other currencies,\n",
    "    which can be important for pricing and market analysis.\n",
    "    \"\"\"\n",
    "    \n",
    "    def fit(self, X: pd.DataFrame, y: Optional[pd.Series] = None) -> 'CurrencyBinary':\n",
    "        \"\"\"Fit method (no-op for this transformer).\"\"\"\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Transform currency information into binary feature.\n",
    "        \n",
    "        Args:\n",
    "            X: Input DataFrame\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame with currency binary feature\n",
    "        \"\"\"\n",
    "        out = X.copy()\n",
    "        \n",
    "        if 'currency_id' in out.columns:\n",
    "            out['is_USD'] = (out['currency_id'] == 'USD').astype('int8')\n",
    "            out = out.drop(columns='currency_id')\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9251696d-2735-43f2-a5ed-e914dc40553f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T00:17:16.871851Z",
     "iopub.status.busy": "2025-07-10T00:17:16.871477Z",
     "iopub.status.idle": "2025-07-10T00:17:16.877550Z",
     "shell.execute_reply": "2025-07-10T00:17:16.877096Z",
     "shell.execute_reply.started": "2025-07-10T00:17:16.871833Z"
    }
   },
   "outputs": [],
   "source": [
    "# ════════════════════════════════════════════════════════════════════════\n",
    "# Pipeline Factory Function\n",
    "# ════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "def make_full_pipeline(target_name: str = 'condition') -> Pipeline:\n",
    "    \"\"\"\n",
    "    Create a complete feature engineering pipeline.\n",
    "    \n",
    "    This function builds a comprehensive preprocessing pipeline that transforms\n",
    "    raw product data into features suitable for machine learning models.\n",
    "    \n",
    "    Args:\n",
    "        target_name: Name of the target column (default: 'condition')\n",
    "        \n",
    "    Returns:\n",
    "        Scikit-learn Pipeline object ready for fitting and transformation\n",
    "        \n",
    "    Example:\n",
    "        >>> pipeline = make_full_pipeline('condition')\n",
    "        >>> X_processed = pipeline.fit_transform(X_train, y_train)\n",
    "        >>> X_test_processed = pipeline.transform(X_test)\n",
    "    \"\"\"\n",
    "    logger.info(\"Creating feature engineering pipeline\")\n",
    "    \n",
    "    pipeline_steps = [\n",
    "        ('drop_initial_cols', DropFeatures(features_to_drop=cast(List[Union[str, int]], COLUMNS_TO_DROP))),\n",
    "        ('normalize_cat_nulls', CatNullNormalizer()),\n",
    "        ('add_time_features', TimeFeatures()),\n",
    "        ('add_numeric_indicators', NumericIndicators()),\n",
    "        ('listing_type_ordinal', ListingTypeOrdinal()),\n",
    "        ('impute_state_missing', CategoricalImputer(\n",
    "            variables=cast(List[Union[str, int]], ['seller_address_state_name']), \n",
    "            imputation_method='missing'\n",
    "        )),\n",
    "        ('rare_labels', RareLabelEncoder(\n",
    "            variables=cast(List[Union[str, int]], ONE_HOT_COLUMNS), \n",
    "            tol=0.01, \n",
    "            n_categories=3, \n",
    "            replace_with='other'\n",
    "        )),\n",
    "        ('add_seller_features', SellerFeatures()),\n",
    "        ('warranty_features', WarrantyTransformer()),\n",
    "        ('attribute_description_flags', AttrDescFlags()),\n",
    "        ('payment_method_features', PaymentMethodFeatures()),\n",
    "        ('picture_count', PictureCount()),\n",
    "        ('tag_features', TagFeatures()),\n",
    "        ('one_hot_nominal', OneHotEncoder(\n",
    "            variables=cast(List[Union[str, int]], ONE_HOT_COLUMNS), \n",
    "            drop_last=False, \n",
    "            ignore_format=True\n",
    "        )),\n",
    "        ('currency_binary', CurrencyBinary()),\n",
    "        ('mean_target_encoder', ce.TargetEncoder(\n",
    "            cols=['category_id'], \n",
    "            smoothing=0.3, \n",
    "            handle_unknown='return_nan'\n",
    "        ))\n",
    "    ]\n",
    "    \n",
    "    return Pipeline(steps=pipeline_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a159523-b088-4222-aa4e-7838176395a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T00:17:16.878347Z",
     "iopub.status.busy": "2025-07-10T00:17:16.878117Z",
     "iopub.status.idle": "2025-07-10T00:17:36.796356Z",
     "shell.execute_reply": "2025-07-10T00:17:36.795839Z",
     "shell.execute_reply.started": "2025-07-10T00:17:16.878330Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Starting feature engineering pipeline demonstration\n",
      "INFO:__main__:Loaded 90000 training samples and 10000 test samples\n",
      "INFO:__main__:Training shape: (90000, 56), Test shape: (10000, 55)\n",
      "INFO:__main__:Creating feature engineering pipeline\n",
      "INFO:__main__:Training data processed: (90000, 44)\n",
      "INFO:__main__:Test data processed: (10000, 44)\n",
      "INFO:__main__:Feature engineering pipeline completed successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "FEATURE ENGINEERING PIPELINE RESULTS\n",
      "============================================================\n",
      "Original training samples: 90,000\n",
      "Original test samples: 10,000\n",
      "Features generated: 44\n",
      "Training shape after FE: (90000, 44)\n",
      "Test shape after FE: (10000, 44)\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ════════════════════════════════════════════════════════════════════════\n",
    "# Main Execution (only when run as script)\n",
    "# ════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to demonstrate pipeline usage.\n",
    "    \n",
    "    This function loads data, creates the pipeline, and processes the data\n",
    "    to show the pipeline in action.\n",
    "    \"\"\"\n",
    "    logger.info(\"Starting feature engineering pipeline demonstration\")\n",
    "    \n",
    "    try:\n",
    "        # Add src directory to Python path\n",
    "        import sys\n",
    "        import os\n",
    "        src_path = os.path.join(os.path.dirname(os.getcwd()), 'src')\n",
    "        if src_path not in sys.path:\n",
    "            sys.path.insert(0, src_path)\n",
    "        \n",
    "        # Import here to avoid circular imports\n",
    "        from new_or_used import build_dataset\n",
    "        \n",
    "        # Load raw data\n",
    "        X_train_raw, y_train, X_test_raw, y_test = build_dataset()\n",
    "        logger.info(f\"Loaded {len(X_train_raw)} training samples and {len(X_test_raw)} test samples\")\n",
    "        \n",
    "        # Convert to DataFrames\n",
    "        df_train = pd.json_normalize(X_train_raw, sep='_')\n",
    "        df_test = pd.json_normalize(X_test_raw, sep='_')\n",
    "        \n",
    "        logger.info(f\"Training shape: {df_train.shape}, Test shape: {df_test.shape}\")\n",
    "        \n",
    "        # Create and fit pipeline\n",
    "        pipeline = make_full_pipeline(target_name='condition')\n",
    "        \n",
    "        # Process training data\n",
    "        X_train_processed = pipeline.fit_transform(df_train.drop(columns='condition'), y_train)\n",
    "        logger.info(f\"Training data processed: {X_train_processed.shape}\")\n",
    "        \n",
    "        # Process test data\n",
    "        X_test_processed = pipeline.transform(df_test)\n",
    "        logger.info(f\"Test data processed: {X_test_processed.shape}\")\n",
    "        \n",
    "        logger.info(\"Feature engineering pipeline completed successfully\")\n",
    "        \n",
    "        # Display feature information\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(\"FEATURE ENGINEERING PIPELINE RESULTS\")\n",
    "        print(f\"{'='*60}\")\n",
    "        print(f\"Original training samples: {len(X_train_raw):,}\")\n",
    "        print(f\"Original test samples: {len(X_test_raw):,}\")\n",
    "        print(f\"Features generated: {X_train_processed.shape[1]}\")\n",
    "        print(f\"Training shape after FE: {X_train_processed.shape}\")\n",
    "        print(f\"Test shape after FE: {X_test_processed.shape}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in pipeline execution: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
